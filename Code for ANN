"""
database_02_98.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A_9E6vOAx26Em2wVEhuSWqITyyuffmQ2
"""

"""
Biocement testing // Biocemented + Cemented and fiber

INPUTS: CEMENT, FIBER, GAMASAT, W, GAMAD, INITIAL VOID RARIO, VOL SOULUTION, 
LOAD, CONFINANT, COUNTERPRESSURE, EFECTIVE.
OUTPUTS: FINAL AXIAL DEF, VOLUMETRIC DEF, p, q, FINAL VOID RATIO
Train // Test // Split
"""

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
from keras.callbacks import EarlyStopping
from keras import metrics
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score


#Importing data
data = pd.read_csv('database_02.csv')

#Scalers
scalerX = MinMaxScaler()
scalerY = MinMaxScaler()

#Setting data // x and y
x = data.iloc[:, 0:11].values
y = data.iloc[:, 11:16].values

scaledX = scalerX.fit_transform(x)
scaledY = scalerY.fit_transform(y)

#Train, test and validation // Splitting validation from x_test and y_test

x_train, x_test, y_train, y_test = train_test_split(scaledX, scaledY, 
                                                   test_size = 0.20)

#Structure
model = Sequential()

model.add(Dense(22, input_dim = 11 , activation="relu", 
                kernel_initializer="normal"))
model.add(Dense(19, activation="relu", 
                kernel_initializer="normal"))
model.add(Dense(19, activation="relu", 
                kernel_initializer="normal"))
model.add(Dense(19, activation="relu", 
                kernel_initializer="normal"))
model.add(Dense(22, activation="relu", 
                kernel_initializer="normal"))

model.add(Dense(5, activation="linear", 
                kernel_initializer="normal"))

model.compile(optimizer='adam', loss='mean_squared_error', 
              metrics=['mse', 'mae', 'mape'])

out = model.fit(x_train, y_train,
                     epochs = 1000,
                     validation_split = 0.20,
                     verbose = 2)

y_pred = model.predict(x_test)
print(y_pred)

#Metrics 
from sklearn.metrics import mean_squared_log_error
y_true_test = y_test

mae = metrics.mean_absolute_error(y_test, y_pred)
print(f'This is mae {mae}')
mse = metrics.mean_squared_error(y_test, y_pred)
print(f'This is mse {mse}')
rmse = np.sqrt(mse).mean()
print(f'This is rmse {rmse}')
r2 = r2_score(y_test, y_pred)
print(f'This is R2 {r2}')

'''
Add Regression loss for that:
ttps://keras.io/api/losses/
'''

#Summarizing history for loss


plt.plot(out.history['loss'])
plt.plot(out.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['validation', 'test'], loc='upper right')
ax = plt.gca()
ax.set_ylim([0, 0.05])
#plt.savefig('test_database_97.png', dpi = 600)
plt.show()
